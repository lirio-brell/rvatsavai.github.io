---
title: "Semi-supervised Learning"
collection: research
---

<ul>
  <li>Our past research has successfully addressed two well-known limitations in remote sensing image classification: 
    limited ground-truth (small or limited training samples) and aggregate classes (e.g., “forest” aggregate class label 
    instead of actual classes like “hard-wood forest”, “coniferous forest”). Semi-supervised learning methods, which are 
    designed to address paucity of labeled samples in classification, assume that both labeled and unlabeled samples come 
    from the same underlying distribution. However, this assumption is violated in remote sensing image classification due 
    to prevalence of aggregate classes. For example, USGS-NLCD uses 21-classes, whereas the USDA-CDL employs more than 100 
    classes in classifying remote sensing data. That is, the number of labeled classes are always less than the total number 
    classes. This violation of in semi-supervised learning leads intraclass variance when the model is learned from pooled 
    labeled and unlabeled samples. To address these challenges, I developed novel algorithms that addressed several subproblems 
    including: (i) finding the optimal number of clusters from the unlabeled data using GX-Means, and (ii) matching classes 
    (labeled samples) and clusters (unlabeled samples) based on the relative entropy principle. Using this approach, samples 
    from additional components (or clusters) can be eliminated or treated as new classes.
  </li>
    <ul>
      <li>Ranga Raju Vatsavai, Christopher T. Symons, Varun Chandola, Goo Jun: GX-Means: A model-based divide and merge 
        algorithm for geospatial image clustering. ICCS 2011: 186-195</li>
      <li>Ranga Raju Vatsavai, Shashi Shekhar, Budhendra L. Bhaduri: A Learning Scheme for Recognizing Sub-classes 
        from Model Trained on Aggregate Classes. SSPR/SPR 2008: 967-976</li>
      <li>Ranga Raju Vatsavai, Shashi Shekhar, Thomas E. Burk: An efficient spatial semi-supervised learning algorithm. 
        Int. J. Parallel Emergent Distributed Syst. 22(6): 427-437 (2007)</li>
    </ul>

  <li>Our present research is exploring the semi-supervised learning in the era of deep learning. Recently we made 
    two significant contributions to address confirmation bias and consistency issues in well-known deep learning models. 
    The Mean Teacher (MT) model is known to suffer from confirmation bias, that is, reinforcing incorrect teacher model predictions.  
    To address this problem, we developed a simple, yet effective method called Local Clustering (LC) to mitigate the effect of 
    confirmation bias. In MT model, each data point is considered independent of other points during training; however, we note 
    that data points are likely to be close to each other in feature space if they share similar features. Motivated by this 
    observation, we cluster data points locally by minimizing the pairwise distance between neighboring data points in feature space. 
    Combined with a standard classification cross-entropy objective on labeled data points, the misclassified unlabeled data points 
    are pulled towards high-density regions of their correct class with the help of their neighbors, thus improving model performance. 
    Thorough experiments on semi-supervised benchmark datasets SVHN and CIFAR-10 showed that adding our LC loss to MT yields significant 
    improvements compared to MT and performance and comparable to the state of the art in semi-supervised learning.
  </li>
  
  <li>
    Generative Adversarial Networks (GANs) based semi-supervised learning (SSL) approaches though shown to improve classification 
    accuracy, their performance is lagging behind the state-of-the-art non-GAN based SSL approaches. We note that the lack of 
    consistency in class probability predictions on the same image under local perturbations is one of the reasons for this 
    performance gap. This problem was addressed in the past in a generic setting using the label consistency regularization, 
    which enforces the class probability predictions for an input image to be unchanged under various semantic-preserving perturbations. 
    We developed a new composite consistency regularization method in the framework of GAN based SSL and demonstrated the efficacy of 
    new approach on two SSL image classification benchmark datasets, SVHN and CIFAR-10. Our experiments show that this new composite 
    consistency regularization based semi-GAN significantly improves its performance and achieves new state-of-the-art performance 
    among GAN-based SSL approaches.
  </li>
  
    <ul>
      <li>Zexi Chen, Benjamin Dutton, Bharathkumar Ramachandra, Tianfu Wu, and Ranga Raju Vatsavai (2020): 
        "Local Clustering with Mean Teacher for Semi-supervised learning." 25th International Conference on Pattern Recognition. 
      </li>
      <li>Zexi Chen, Bharathkumar Ramachandra, Ranga Raju Vatsavai (2020): Consistency Regularization with Generative Adversarial 
        Networks for Semi-Supervised Image Classification. CoRR abs/2007.03844
      </li>   
    </ul>
</ul>
